{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch run on SPARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy\n",
    "import dipy.reconst.dti as dti\n",
    "from diGP.preprocessing_pipelines import get_SPARC_train_and_test\n",
    "from diGP.dataManipulations import DataHandler\n",
    "from diGP.model import Model, get_default_kernel, get_default_independent_kernel\n",
    "from diGP.evaluation import get_SPARC_metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../config.json', 'r') as json_file:\n",
    "    conf = json.load(json_file)\n",
    "data_paths = conf['SPARC']['data_paths']\n",
    "q_test_path = conf['SPARC']['q_test_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = 'gradient_20'\n",
    "gtab, data, voxelSize = get_SPARC_train_and_test(data_paths[source], data_paths['goldstandard'], q_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the various configurations to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = ['', 'DTI', 'MAPL']\n",
    "n_max = [0, 2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit regular DTI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tenmodel = dti.TensorModel(gtab['train'])\n",
    "tenfit = tenmodel.fit(data['train'])\n",
    "\n",
    "fitted = {'DTI': tenfit.predict(gtab['train'])}\n",
    "pred = {'DTI': tenfit.predict(gtab['test'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load precomputed MAPL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted['MAPL'] = np.load(os.path.join(data_paths[source], 'map_mri_train.npy'))\n",
    "pred['MAPL'] = np.load(os.path.join(data_paths[source], 'map_mri_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify dummy model for the case with no mean function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitted[''] = np.zeros_like(fitted['DTI'])\n",
    "pred[''] = np.zeros_like(pred['DTI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_predict(handler, handlerPred, kernel):\n",
    "    model = Model(handler, kernel, data_handler_pred=handlerPred, grid_dims=[[0], [1], [2, 3, 4, 5]], verbose=False)\n",
    "    model.train(restarts=False) \n",
    "    \n",
    "    #seed = 1\n",
    "    #np.random.seed(seed)\n",
    "    #while True:\n",
    "    #    try:\n",
    "    #        model = Model(handler, kernel, data_handler_pred=handlerPred, grid_dims=[[0], [1], [2, 3, 4, 5]], verbose=False)\n",
    "    #        #model.train(restarts=True, num_restarts=2, robust=True, parallel=False)\n",
    "    #        model.train(restarts=False, optimizer=None)          \n",
    "    #        \n",
    "    #        print('Optimized parameters:\\n {}'.format(model.GP_model.kern.param_array))\n",
    "    #        break\n",
    "    #    except:\n",
    "    #        print(\"\\nOptimization failed, retrying.\")\n",
    "    #        seed += 1\n",
    "    #        np.random.seed(seed)\n",
    "    #        continue\n",
    "    \n",
    "    out = model.predict(compute_var=False)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vary the maximum order of the Legendre polynomials, without spatial correlations\n",
    "for base_model in mean:\n",
    "    handler = DataHandler(gtab['train'], data=data['train'], mean=fitted[base_model], voxelSize=voxelSize[0:2])\n",
    "    handlerPred = DataHandler(gtab['test'], data=None, mean=pred[base_model],\n",
    "                              spatial_shape=data['test'].shape[0:2], voxelSize=voxelSize[0:2])\n",
    "    \n",
    "    for n in n_max:\n",
    "        if base_model == '':\n",
    "            name = 'GP_n{}_indep'.format(n)\n",
    "        else:\n",
    "            name = \"{} + GP_n{}_indep\".format(base_model, n)\n",
    "        \n",
    "        print('\\nRunning {}'.format(name))\n",
    "        kernel = get_default_independent_kernel(handler, n)\n",
    "        \n",
    "        pred[name] = train_and_predict(handler, handlerPred, kernel)\n",
    "\n",
    "        get_SPARC_metrics(gtab['test'], data['test'], pred[name], verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vary the maximum order of the Legendre polynomials, with spatial correlations\n",
    "for base_model in mean:\n",
    "    handler = DataHandler(gtab['train'], data=data['train'], mean=fitted[base_model], voxelSize=voxelSize[0:2])\n",
    "    handlerPred = DataHandler(gtab['test'], data=None, mean=pred[base_model],\n",
    "                              spatial_shape=data['test'].shape[0:2], voxelSize=voxelSize[0:2])\n",
    "    \n",
    "    for n in n_max:\n",
    "        if base_model == '':\n",
    "            name = 'GP_n{}'.format(n)\n",
    "        else:\n",
    "            name = \"{} + GP_n{}\".format(base_model, n)\n",
    "        \n",
    "        print('\\nRunning {}'.format(name))\n",
    "        kernel = get_default_kernel(handler, n_max=n)\n",
    "        \n",
    "        pred[name] = train_and_predict(handler, handlerPred, kernel)\n",
    "\n",
    "        get_SPARC_metrics(gtab['test'], data['test'], pred[name], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_paths[source], 'batch_run_prediction_results.p'), 'wb') as fp:\n",
    "    pickle.dump(pred, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_paths[source], 'batch_run_prediction_results.p'), 'rb') as fp:\n",
    "    pred = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NMSE_low = {}\n",
    "NMSE_high = {}\n",
    "for key in sorted(pred.keys()):\n",
    "    this_NMSE_low, this_NMSE_high, _ = get_SPARC_metrics(gtab['test'], data['test'], pred[key], verbose=False)\n",
    "    NMSE_low[key] = this_NMSE_low\n",
    "    NMSE_high[key] = this_NMSE_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GP_low = np.array([NMSE_low['GP_n0'], NMSE_low['GP_n2'], NMSE_low['GP_n4'], NMSE_low['GP_n6'], NMSE_low['GP_n8']])\n",
    "GP_high = np.array([NMSE_high['GP_n0'], NMSE_high['GP_n2'], NMSE_high['GP_n4'], NMSE_high['GP_n6'], NMSE_high['GP_n8']])\n",
    "\n",
    "GP_indep_low = np.array([NMSE_low['GP_n0_indep'], NMSE_low['GP_n2_indep'], NMSE_low['GP_n4_indep'],\n",
    "                         NMSE_low['GP_n6_indep'], NMSE_low['GP_n8_indep']])\n",
    "GP_indep_high = np.array([NMSE_high['GP_n0_indep'], NMSE_high['GP_n2_indep'], NMSE_high['GP_n4_indep'],\n",
    "                         NMSE_high['GP_n6_indep'], NMSE_high['GP_n8_indep']])\n",
    "\n",
    "DTI_GP_low = np.array([NMSE_low['DTI + GP_n0'], NMSE_low['DTI + GP_n2'], NMSE_low['DTI + GP_n4'],\n",
    "                       NMSE_low['DTI + GP_n6'], NMSE_low['DTI + GP_n8']])\n",
    "DTI_GP_high = np.array([NMSE_high['DTI + GP_n0'], NMSE_high['DTI + GP_n2'], NMSE_high['DTI + GP_n4'],\n",
    "                        NMSE_high['DTI + GP_n6'], NMSE_high['DTI + GP_n8']])\n",
    "\n",
    "DTI_GP_indep_low = np.array([NMSE_low['DTI + GP_n0_indep'], NMSE_low['DTI + GP_n2_indep'], NMSE_low['DTI + GP_n4_indep'],\n",
    "                         NMSE_low['DTI + GP_n6_indep'], NMSE_low['DTI + GP_n8_indep']])\n",
    "DTI_GP_indep_high = np.array([NMSE_high['DTI + GP_n0_indep'], NMSE_high['DTI + GP_n2_indep'], NMSE_high['DTI + GP_n4_indep'],\n",
    "                         NMSE_high['DTI + GP_n6_indep'], NMSE_high['DTI + GP_n8_indep']])\n",
    "\n",
    "MAPL_GP_low = np.array([NMSE_low['MAPL + GP_n0'], NMSE_low['MAPL + GP_n2'], NMSE_low['MAPL + GP_n4'],\n",
    "                        NMSE_low['MAPL + GP_n6'], NMSE_low['MAPL + GP_n8']])\n",
    "MAPL_GP_high = np.array([NMSE_high['MAPL + GP_n0'], NMSE_high['MAPL + GP_n2'], NMSE_high['MAPL + GP_n4'],\n",
    "                        NMSE_high['MAPL + GP_n6'], NMSE_high['MAPL + GP_n8']])\n",
    "\n",
    "MAPL_GP_indep_low = np.array([NMSE_low['MAPL + GP_n0_indep'], NMSE_low['MAPL + GP_n2_indep'], NMSE_low['MAPL + GP_n4_indep'],\n",
    "                        NMSE_low['MAPL + GP_n6_indep'], NMSE_low['MAPL + GP_n8_indep']])\n",
    "MAPL_GP_indep_high = np.array([NMSE_high['MAPL + GP_n0_indep'], NMSE_high['MAPL + GP_n2_indep'], NMSE_high['MAPL + GP_n4_indep'],\n",
    "                        NMSE_high['MAPL + GP_n6_indep'], NMSE_high['MAPL + GP_n8_indep']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(n_max, GP_low, 'b-', n_max, GP_indep_low, 'b--',\n",
    "           0, NMSE_low['DTI'], 'go', n_max, DTI_GP_low, 'g-', n_max, DTI_GP_indep_low, 'g--',\n",
    "           0, NMSE_low['MAPL'], 'ro', n_max, MAPL_GP_low, 'r-', n_max, MAPL_GP_indep_low, 'r--')\n",
    "\n",
    "\n",
    "plt.axis([-0.5, 8.5, 0, 0.25])\n",
    "plt.xticks(n_max)\n",
    "plt.xlabel('Angular order')\n",
    "plt.ylabel('NMSE')\n",
    "\n",
    "# Shrink current axis by 20% to match size of the next figure\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.savefig('NMSE_low.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(n_max, GP_high, 'b-', label='GP')\n",
    "plt.plot(n_max, GP_indep_high, 'b--', label='GP (independent voxels)')\n",
    "plt.plot(0, NMSE_high['DTI'], 'go', label='DTI')\n",
    "plt.plot(n_max, DTI_GP_high, 'g-', label='DTI + GP')\n",
    "plt.plot(n_max, DTI_GP_indep_high, 'g--', label='DTI + GP (independent voxels)')\n",
    "plt.plot(0, NMSE_high['MAPL'], 'ro', label='MAPL')\n",
    "plt.plot(n_max, MAPL_GP_high, 'r-', label='MAPL + GP')\n",
    "plt.plot(n_max, MAPL_GP_indep_high, 'r--', label='MAPL + GP (independent voxels)')\n",
    "         \n",
    "plt.axis([-0.5, 8.5, 0, 0.25])\n",
    "plt.xticks(n_max)\n",
    "plt.xlabel('Angular order')\n",
    "plt.ylabel('NMSE')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# Shrink current axis by 20%\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "lgd = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5));\n",
    "plt.savefig('NMSE_high.png', transparent=True, bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "ax[0].plot(n_max, GP_low, 'b-', n_max, GP_indep_low, 'b--',\n",
    "           0, NMSE_low['DTI'], 'go', n_max, DTI_GP_low, 'g-', n_max, DTI_GP_indep_low, 'g--',\n",
    "           0, NMSE_low['MAPL'], 'ro', n_max, MAPL_GP_low, 'r-', n_max, MAPL_GP_indep_low, 'r--')\n",
    "\n",
    "ax[1].plot(n_max, GP_high, 'b-', label='GP')\n",
    "ax[1].plot(n_max, GP_indep_high, 'b--', label='GP (independent voxels)')\n",
    "ax[1].plot(0, NMSE_high['DTI'], 'go', label='DTI')\n",
    "ax[1].plot(n_max, DTI_GP_high, 'g-', label='DTI + GP')\n",
    "ax[1].plot(n_max, DTI_GP_indep_high, 'g--', label='DTI + GP (independent voxels)')\n",
    "ax[1].plot(0, NMSE_high['MAPL'], 'ro', label='MAPL')\n",
    "ax[1].plot(n_max, MAPL_GP_high, 'r-', label='MAPL + GP')\n",
    "ax[1].plot(n_max, MAPL_GP_indep_high, 'r--', label='MAPL + GP (independent voxels)')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis([-0.5, 8.5, 0, 0.25])\n",
    "    a.set_xticks(n_max)\n",
    "    a.set_xlabel('Angular order')\n",
    "    a.set_ylabel('NMSE')\n",
    "\n",
    "    a.spines['right'].set_visible(False)\n",
    "    a.spines['top'].set_visible(False)\n",
    "    box = a.get_position()\n",
    "    a.set_position([box.x0, box.y0, box.width, box.height])\n",
    "\n",
    "lgd = ax[1].legend(loc='upper center', bbox_to_anchor=(-0.2, -0.2), ncol=4)\n",
    "fig.tight_layout(w_pad=5)\n",
    "plt.savefig('NMSE.png', transparent=True, bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
